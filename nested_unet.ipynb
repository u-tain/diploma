{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import torch.nn as nn \n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "_uuid": "527c5b86-199c-47c0-817d-fdaf62e989eb",
    "_cell_guid": "aee6e758-eacb-4feb-99d0-ceb3a28d42b2",
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:08.812252Z",
     "iopub.execute_input": "2022-06-03T01:28:08.812574Z",
     "iopub.status.idle": "2022-06-03T01:28:29.353463Z",
     "shell.execute_reply.started": "2022-06-03T01:28:08.812484Z",
     "shell.execute_reply": "2022-06-03T01:28:29.352632Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\nd = {'ImageId': df['ImageId'].unique()}\ntrain_df = pd.DataFrame(d)\ntrain_df['ClassesList'] = ['' for i in range(len(train_df))]\ntrain_df['EncodedPixels'] = ['' for i in range(len(train_df))]\nfor i in range(len(train_df)):\n    train_df['ClassesList'][i] = df.loc[df['ImageId']==train_df['ImageId'][i]]['ClassId'].values.tolist()\n    train_df['EncodedPixels'][i] = df.loc[df['ImageId']==train_df['ImageId'][i]]['EncodedPixels'].values.tolist()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:29.355346Z",
     "iopub.execute_input": "2022-06-03T01:28:29.355778Z",
     "iopub.status.idle": "2022-06-03T01:28:52.90863Z",
     "shell.execute_reply.started": "2022-06-03T01:28:29.355727Z",
     "shell.execute_reply": "2022-06-03T01:28:52.907898Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def make_mask( encoded, shape=(1600,256)):\n    # Делим на два списка в соответствии с кодировкой\n    if isinstance(encoded, str):\n        encoded = list(map(int, encoded.split(' ')))\n#     print(encoded)\n    full,pixel,number = [],[],[]\n    [pixel.append(encoded[i]) if i%2==0 else number.append(encoded[i]) for i in range(0, len(encoded))]\n    # \"Раскрываем\" кодировку, получаем индексы закрашенных пикселей\n    k=0\n    for i in range(len(number)):\n        for j in range(number[i]):\n            ind = pixel[i]+j\n            full.append(ind-1)\n        k +=number[i]\n    # Создаем массив под готовое изображение    \n    mask = np.zeros((1600*256,1), dtype=int)\n    # Закрашиваем соответствующие пиксели\n    mask[full] = 255\n    #преобразем к размерам фотографий металла\n    res = np.reshape(mask,(1600, 256)).T\n    res = Image.fromarray(res.astype(np.uint8))\n    return res",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:52.909939Z",
     "iopub.execute_input": "2022-06-03T01:28:52.910199Z",
     "iopub.status.idle": "2022-06-03T01:28:52.91864Z",
     "shell.execute_reply.started": "2022-06-03T01:28:52.910166Z",
     "shell.execute_reply": "2022-06-03T01:28:52.917828Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:52.920974Z",
     "iopub.execute_input": "2022-06-03T01:28:52.921449Z",
     "iopub.status.idle": "2022-06-03T01:28:52.999534Z",
     "shell.execute_reply.started": "2022-06-03T01:28:52.921413Z",
     "shell.execute_reply": "2022-06-03T01:28:52.998758Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# разные режимы датасета \nDATA_MODES = ['train', 'val', 'test']\n# все изображения будут масштабированы к размеру 224x224 px\nRESCALE_SIZE_1 = 800\nRESCALE_SIZE_2 = 128\n# работаем на видеокарте\nDEVICE = torch.device(\"cuda\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.001495Z",
     "iopub.execute_input": "2022-06-03T01:28:53.002211Z",
     "iopub.status.idle": "2022-06-03T01:28:53.00761Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.002167Z",
     "shell.execute_reply": "2022-06-03T01:28:53.006933Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class SteelDataset(Dataset):\n    def __init__(self, names, df, mode):\n        super().__init__()\n        self.names = names\n        self.mode = mode\n        if self.mode != 'test':\n            self.df = df\n\n        if self.mode not in DATA_MODES:\n            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n            raise NameError\n\n        self.len_ = len(self.names)\n        \n    def __len__(self):\n        return self.len_\n      \n    def load_sample(self, file, mode):\n        if mode == 'test':\n            image = Image.open('../input/severstal-steel-defect-detection/test_images/'+ file).convert(\"RGB\")\n        else:\n            image = Image.open('../input/severstal-steel-defect-detection/train_images/'+ file).convert(\"RGB\")\n        image.load()\n        return image\n    \n    def __getitem__(self, index):\n            transforms_tens = T.Compose([\n            T.ToTensor()])\n\n            # загружаем и меняем размер изображения\n            img = self._prepare_sample(self.load_sample(self.names[index], self.mode))\n\n            if self.mode == 'test':\n                img = np.array(img)\n                max_value = 256 ** ((img.dtype == np.uint16) + 1) - 1\n                img = (img / max_value).astype(np.float32)\n                img = transforms_tens(img)\n                return img\n            \n            # загружаем классы и маски\n            labels = list(self.df['ClassesList'].loc[self.df['ImageId'] == self.names[index]])[0]\n            mask = list(self.df['EncodedPixels'].loc[self.df['ImageId'] == self.names[index]])[0]\n            num_obj = len(labels)\n            masks = np.zeros((RESCALE_SIZE_2, RESCALE_SIZE_1, 4), dtype=np.float32)\n            masks = np.transpose(masks,(2, 0, 1))\n            for i in range(4):\n                for j in range(num_obj):\n                    if i == (labels[j]-1):\n                # раскодирование масок\n                        masks[i] = np.array(self._prepare_sample(make_mask(mask[j])))\n                        masks[i] = masks[i] / 255\n\n            # преобазование в тензоры\n            masks = torch.as_tensor(masks, dtype=torch.float32)\n            label = torch.as_tensor(labels)\n            \n            # преобразуем изображения и маски\n            if self.mode == \"train\":\n                img, masks= transforms_all(img,masks)\n                \n            img = np.array(img)\n            max_value = 256 ** ((img.dtype == np.uint16) + 1) - 1\n            img = (img / max_value).astype(np.float32)\n            img = transforms_tens(img)\n            \n            return img, masks\n        \n    def _prepare_sample(self, image):\n        image = image.resize((RESCALE_SIZE_1, RESCALE_SIZE_2))\n        return image",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:40:47.8205Z",
     "iopub.execute_input": "2022-06-03T01:40:47.821189Z",
     "iopub.status.idle": "2022-06-03T01:40:47.84032Z",
     "shell.execute_reply.started": "2022-06-03T01:40:47.821141Z",
     "shell.execute_reply": "2022-06-03T01:40:47.839628Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def transforms_all(image, segmentation):\n    if random.random() > 0.5:\n        image = TF.autocontrast(image)\n    if random.random() > 0.5:\n        image = TF.hflip(image)\n        segmentation = TF.hflip(segmentation)\n    if random.random() > 0.5:\n        image = TF.vflip(image)\n        segmentation = TF.vflip(segmentation)\n    return image, segmentation",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.031144Z",
     "iopub.execute_input": "2022-06-03T01:28:53.031446Z",
     "iopub.status.idle": "2022-06-03T01:28:53.042301Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.03141Z",
     "shell.execute_reply": "2022-06-03T01:28:53.041517Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\ntrain_val_names = train_df['ImageId']\ntrain_files,val_files = train_test_split(train_val_names, train_size=0.75)\nval_dataset = SteelDataset(list(val_files), train_df,  mode='val')\ntrain_dataset = SteelDataset(list(train_files),train_df, mode='train')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:40:52.020744Z",
     "iopub.execute_input": "2022-06-03T01:40:52.021289Z",
     "iopub.status.idle": "2022-06-03T01:40:52.030355Z",
     "shell.execute_reply.started": "2022-06-03T01:40:52.021251Z",
     "shell.execute_reply": "2022-06-03T01:40:52.029487Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def fit_epoch(model, train_loader, criterion, optimizer, batch_size):\n    model.train()\n    running_loss = 0.0\n    dice = 0.0\n    iou = 0.0\n    for X_batch, Y_batch in train_loader:\n        inputs = X_batch.to(DEVICE)\n        labels = Y_batch.to(DEVICE)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs,labels.long())\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.detach().cpu().numpy() \n        dice += dice_metric(outputs, labels)\n    train_loss = running_loss / len(train_loader)\n    train_dice = dice / len(train_loader)\n    return train_loss, train_dice",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:29:20.450085Z",
     "iopub.execute_input": "2022-06-03T01:29:20.450338Z",
     "iopub.status.idle": "2022-06-03T01:29:20.457821Z",
     "shell.execute_reply.started": "2022-06-03T01:29:20.450308Z",
     "shell.execute_reply": "2022-06-03T01:29:20.45683Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def eval_epoch(model, val_loader, criterion, batch_size):\n    model.eval()\n    dice = 0.0\n    iou = 0.0\n    running_loss = 0.0\n    for X_batch, Y_batch in val_loader:\n        inputs = X_batch.to(DEVICE)\n        labels = Y_batch.to(DEVICE)\n\n        with torch.no_grad():\n            outputs = model(inputs)\n            loss = criterion(outputs,labels.long())\n            running_loss += loss.item()\n            dice += dice_metric(outputs, labels)\n    val_loss = running_loss / len(val_loader)\n    val_dice = dice / len(val_loader)\n\n    return val_loss, val_dice",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:29:23.758117Z",
     "iopub.execute_input": "2022-06-03T01:29:23.758375Z",
     "iopub.status.idle": "2022-06-03T01:29:23.7654Z",
     "shell.execute_reply.started": "2022-06-03T01:29:23.758347Z",
     "shell.execute_reply": "2022-06-03T01:29:23.764715Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def train(train_files, val_files, model, epochs, batch_size):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers = 2, shuffle=True)#,collate_fn = collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size,num_workers = 2, shuffle=False)#,collate_fn = collate_fn)\n    history = []\n    maxIoU = 0\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} train_dice: {t_dice:0.4f} \\\n    \\nValidation  val_loss: {v_loss:0.4f} val_dice: {v_dice:0.4f} \"\n    criterion = nn.BCEWithLogitsLoss()\n    \n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        params = model.parameters()\n        opt = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n        lr_scheduler = torch.optim.lr_scheduler.StepLR(opt,\n                                                   step_size=20,\n                                                   gamma=0.1)\n        for epoch in range(epochs):\n            train_loss, train_dice = fit_epoch(model, train_loader, criterion, opt, batch_size)\n            lr_scheduler.step()    \n            val_loss, val_dice = eval_epoch(model, val_loader, criterion, batch_size)\n            history.append((train_loss, train_dice, val_loss, val_dice))\n            if val_IoU > maxIoU:\n                maxIoU = val_IoU\n                torch.save(model, './weight_unet.dat')\n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss, t_dice = train_dice, \\\n                                           v_loss=val_loss, v_dice = val_acc ))   \n    return history",
   "metadata": {
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2022-06-03T01:29:25.703388Z",
     "iopub.execute_input": "2022-06-03T01:29:25.704061Z",
     "iopub.status.idle": "2022-06-03T01:29:25.71363Z",
     "shell.execute_reply.started": "2022-06-03T01:29:25.704023Z",
     "shell.execute_reply": "2022-06-03T01:29:25.71295Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def dice_metric(probability, truth, threshold=0.5, reduction='none'):\n    batch_size = len(truth)\n    with torch.no_grad():\n        probability = probability.view(batch_size, -1)\n        truth = truth.view(batch_size, -1)\n        assert(probability.shape == truth.shape)\n\n        p = (probability > threshold).float()\n        t = truth.float()\n\n        t_sum = t.sum(-1)\n        p_sum = p.sum(-1)\n        neg_index = torch.nonzero(t_sum == 0)\n        pos_index = torch.nonzero(t_sum >= 1)\n\n        dice_neg = (p_sum == 0).float()\n        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n\n        dice_neg = dice_neg[neg_index]\n        dice_pos = dice_pos[pos_index]\n        dice = dice_pos\n    return dice",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.681282Z",
     "iopub.status.idle": "2022-06-03T01:28:53.681681Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.681462Z",
     "shell.execute_reply": "2022-06-03T01:28:53.681484Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class UnetConv2dBlock(nn.Module):\n\n    def __init__(self, in_channel: int, mid_channel: int, out_channel: int, kernel_size: list = [3,3], stride_size: list = [1,1], activation: str = 'relu'):\n        super().__init__()\n\n        if activation == 'swish':\n            self.conv2dblock = nn.Sequential(\n            nn.Conv2d(in_channel, mid_channel, kernel_size=kernel_size[0], stride=stride_size[0], padding=1),\n            nn.BatchNorm2d(mid_channel),\n            Swish(),\n            nn.Conv2d(mid_channel, out_channel, kernel_size=kernel_size[1], stride=stride_size[1], padding=1),\n            nn.BatchNorm2d(out_channel),\n            Swish(),\n        )\n        else:\n            self.conv2dblock = nn.Sequential(\n                nn.Conv2d(in_channel, mid_channel, kernel_size=kernel_size[0], stride=stride_size[0], padding=1),\n                nn.BatchNorm2d(mid_channel),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(mid_channel, out_channel, kernel_size=kernel_size[1], stride=stride_size[1], padding=1),\n                nn.BatchNorm2d(out_channel),\n                nn.ReLU(inplace=True)\n            )\n\n    def forward(self, x):\n        return self.conv2dblock(x)\n\n\n\nclass Swish(nn.Module):\n\n    def __init__(self, slope = 1):\n        super().__init__()\n        self.slope = slope # * torch.nn.Parameter(torch.ones(1))\n\n    def forward(self, x):\n        return self.slope * x * torch.sigmoid(x)\n\n\n\nclass DownSample(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.maxpooling = nn.MaxPool2d(2)\n\n    def forward(self, x):\n        return self.maxpooling(x)\n\n\n\nclass UpSample(nn.Module):\n\n    def __init__(self, in_channel=None, bilinear: bool = True):\n        super().__init__()\n\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        else:\n            self.up = nn.ConvTranspose2d(in_channel , in_channel // 2, kernel_size=2, stride=2)\n\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        \n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        x = torch.cat([x2, x1], dim=1)\n        return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.690841Z",
     "iopub.status.idle": "2022-06-03T01:28:53.691252Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.691031Z",
     "shell.execute_reply": "2022-06-03T01:28:53.691053Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class UnetPlusPlus(nn.Module):\n    \n    def __init__(self, in_channel, num_classes: int, deep_supervision: bool=False):\n        super(UnetPlusPlus, self).__init__()\n        self.num_classes = num_classes\n        self.metrics = 0 \n        self.deep_supervision = deep_supervision\n\n        num_filter = [32, 64, 128, 256, 512]\n\n        self.down = DownSample()\n        self.up = UpSample()\n\n        self.conv_block_0_0 = UnetConv2dBlock(in_channel, num_filter[0], num_filter[0])\n        self.conv_block_1_0 = UnetConv2dBlock(num_filter[0], num_filter[1], num_filter[1])\n        self.conv_block_2_0 = UnetConv2dBlock(num_filter[1], num_filter[2], num_filter[2])\n        self.conv_block_3_0 = UnetConv2dBlock(num_filter[2], num_filter[3], num_filter[3])\n        \n        self.conv_block_0_1 = UnetConv2dBlock(num_filter[0]+num_filter[1], num_filter[0], num_filter[0])\n        self.conv_block_1_1 = UnetConv2dBlock(num_filter[1]+num_filter[2], num_filter[1], num_filter[1])\n        self.conv_block_2_1 = UnetConv2dBlock(num_filter[2]+num_filter[3], num_filter[2], num_filter[2])\n\n        self.conv_block_0_2 = UnetConv2dBlock(2*num_filter[0]+num_filter[1], num_filter[0], num_filter[0])\n        self.conv_block_1_2 = UnetConv2dBlock(2*num_filter[1]+num_filter[2], num_filter[1], num_filter[1])\n\n        self.conv_block_0_3 = UnetConv2dBlock(3*num_filter[0]+num_filter[1], num_filter[0], num_filter[0])\n\n        if self.deep_supervision:\n            self.final1 = nn.Conv2d(num_filter[0], self.num_classes, kernel_size=1)\n            self.final2 = nn.Conv2d(num_filter[0], self.num_classes, kernel_size=1)\n            self.final3 = nn.Conv2d(num_filter[0], self.num_classes, kernel_size=1)\n        else:\n            self.final = nn.Conv2d(num_filter[0], self.num_classes, kernel_size=1)\n\n    def forward(self, x):\n\n        x0_0 = self.conv_block_0_0(x)\n\n        x1_0 = self.conv_block_1_0(self.down(x0_0))\n        x0_1 = self.conv_block_0_1(self.up(x1_0, x0_0))\n        \n        x2_0 = self.conv_block_2_0(self.down(x1_0))\n        x1_1 = self.conv_block_1_1(self.up(x2_0, x1_0))\n        x0_2 = self.conv_block_0_2(self.up(x1_1, torch.cat([x0_0, x0_1], 1)))\n\n        x3_0 = self.conv_block_3_0(self.down(x2_0))\n        x2_1 = self.conv_block_2_1(self.up(x3_0, x2_0))\n        x1_2 = self.conv_block_1_2(self.up(x2_1, torch.cat([x1_0, x1_1],1)))\n        x0_3 = self.conv_block_0_3(self.up(x1_2, torch.cat([x0_0, x0_1, x0_2], 1)))\n\n        if self.deep_supervision:\n            output1 = self.final1(x0_1)\n            output2 = self.final2(x0_2)\n            output3 = self.final3(x0_3)\n            return [output1, output2, output3]\n\n        else:\n            out = self.final(x0_3)\n            return out",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.692857Z",
     "iopub.status.idle": "2022-06-03T01:28:53.693318Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.693094Z",
     "shell.execute_reply": "2022-06-03T01:28:53.693117Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model = UnetPlusPlus(3,4).to(DEVICE)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.694758Z",
     "iopub.status.idle": "2022-06-03T01:28:53.695191Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.69496Z",
     "shell.execute_reply": "2022-06-03T01:28:53.694983Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "history = train(train_dataset, val_dataset, model, epochs = 53, batch_size = 5)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:29:40.72173Z",
     "iopub.execute_input": "2022-06-03T01:29:40.722287Z",
     "iopub.status.idle": "2022-06-03T01:34:48.318026Z",
     "shell.execute_reply.started": "2022-06-03T01:29:40.722246Z",
     "shell.execute_reply": "2022-06-03T01:34:48.316714Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_loss, train_acc, val_loss, val_acc = zip(*history)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.700235Z",
     "iopub.status.idle": "2022-06-03T01:28:53.700943Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.700694Z",
     "shell.execute_reply": "2022-06-03T01:28:53.70072Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,13))\n    ax1.plot(train_loss, label='train', marker='o')\n    ax1.plot(val_loss, label='val', marker='o')\n    ax1.set_title('Loss per epoch')\n    ax1.set_ylabel('loss');\n    ax1.set_xlabel('epoch')\n    ax1.legend(), ax1.grid()\n    \n    ax2.plot(train_dice, label='train_dice', marker='*')\n    ax2.plot(val_dice, label='val_dice',  marker='*')\n    ax2.set_title('Score per epoch')\n    ax2.set_ylabel('mean dice')\n    ax2.set_xlabel('epoch')\n    ax2.legend(), ax2.grid()\n    \n#     plt.savefig('0.710615.png')\n    plt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.706276Z",
     "iopub.status.idle": "2022-06-03T01:28:53.706675Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.706457Z",
     "shell.execute_reply": "2022-06-03T01:28:53.706479Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def predict_image_mask_miou(model, image, mask):\n    model.eval()\n    \n    image = image.to(DEVICE)\n    mask = mask.to(DEVICE)\n    with torch.no_grad():\n        \n        image = image.unsqueeze(0)\n        mask = mask.unsqueeze(0)\n        \n        output = model(image)\n        print(output)\n        score = dice_metric(output, mask)\n        masked = torch.argmax(output, dim=1)\n        masked = masked.cpu().squeeze(0)\n    return masked, score",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.707846Z",
     "iopub.status.idle": "2022-06-03T01:28:53.70882Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.708562Z",
     "shell.execute_reply": "2022-06-03T01:28:53.708587Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def miou_score(model, val_dataset):\n    score_iou = []\n    for i in tqdm(range(len(val_dataset))):\n        img, mask = val_dataset[i]\n        pred_mask, score = predict_image_mask_miou(model, img, mask)\n        score_iou.append(score)\n    return score_iou",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.710223Z",
     "iopub.status.idle": "2022-06-03T01:28:53.710621Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.710403Z",
     "shell.execute_reply": "2022-06-03T01:28:53.710425Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# model = torch.load('../input/unet-weight/weight_unet_wew.dat')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.714024Z",
     "iopub.status.idle": "2022-06-03T01:28:53.714435Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.714219Z",
     "shell.execute_reply": "2022-06-03T01:28:53.714241Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(np.mean(miou_score(model, val_dataset)))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T01:28:53.715966Z",
     "iopub.status.idle": "2022-06-03T01:28:53.716372Z",
     "shell.execute_reply.started": "2022-06-03T01:28:53.716157Z",
     "shell.execute_reply": "2022-06-03T01:28:53.71618Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}